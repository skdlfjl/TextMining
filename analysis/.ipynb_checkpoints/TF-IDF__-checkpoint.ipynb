{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 분석2-2. TF-IDF (least_word + over_word 삭제한 token 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 각 카테고리의 데이터 개수(채용공고의 개수)를 가져와서 튜플형태로 저장한 뒤, 리스트에 넣는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 746), (1, 683), (2, 624), (3, 494), (4, 287), (5, 274), (6, 256), (7, 233), (8, 220), (9, 193), (10, 163), (11, 148), (12, 168), (13, 141), (14, 171), (15, 162), (16, 137), (17, 109)]\n"
     ]
    }
   ],
   "source": [
    "category_len = []\n",
    "\n",
    "for category_num in range(18):\n",
    "    data = open('../crawling_all_1211/category{0}.txt'.format(category_num), 'r', encoding = 'utf-8')\n",
    "    lines = data.readlines()  # 데이터 불러와서 line 단위로 넣는다\n",
    "    #print(len(lines))\n",
    "    tu = category_num, len(lines)\n",
    "    category_len.append(tu)\n",
    "    \n",
    "print(category_len)# ( 카테고리번호, 크롤링 데이터 개수 ) 모양의 튜플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 총 18개의 크롤링 데이터(클렌징까지 마침)를 불러와서, category_sum 리스트에 넣어줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category_num, data_num in category_len:\n",
    "    \n",
    "    data = open('../cleansing_all_1211/data_cleansing_all/cleansing_category{0}_list{1}.txt'.format(category_num, data_num), 'r', encoding = 'utf-8')\n",
    "    data = data.readlines()  # 데이터 불러와서 line 단위로 넣는다\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        data[i] = data[i].replace('\\n', '')    # 각 문장마다 들어있는 줄바꿈 기호 없애주기\n",
    "    \n",
    "    data = ' '.join(data)\n",
    "    \n",
    "    ## 각 변수에 저장하자\n",
    "    globals()['category{}'.format(category_num)] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_sum = []\n",
    "\n",
    "for category_num in range(18):\n",
    "    category = globals()['category{}'.format(category_num)]\n",
    "    category_sum.append(category)\n",
    "    \n",
    "len(category_sum) # 총 18개의 크롤링 데이터를 차례대로 category_sum 리스트에 넣어줬다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## vocabulary_all_1211 디렉토리 안의 tokens{}_.txt를 가져옵니다 (전처리가 완료된 토큰)\n",
    "\n",
    "# tokens{}: {}카테고리의 전처리 완료된 전체 토큰\n",
    "# voca{}: {}카테고리의 유니트 토큰\n",
    "\n",
    "# common_voca: 전체 데이터(1211) 공통등장 voca(토큰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0 번째 category (tokens): 29217\n",
      "# voca size: 1205 \n",
      "\n",
      "# 1 번째 category (tokens): 24087\n",
      "# voca size: 1108 \n",
      "\n",
      "# 2 번째 category (tokens): 23699\n",
      "# voca size: 1070 \n",
      "\n",
      "# 3 번째 category (tokens): 17254\n",
      "# voca size: 872 \n",
      "\n",
      "# 4 번째 category (tokens): 8976\n",
      "# voca size: 576 \n",
      "\n",
      "# 5 번째 category (tokens): 8389\n",
      "# voca size: 539 \n",
      "\n",
      "# 6 번째 category (tokens): 8202\n",
      "# voca size: 552 \n",
      "\n",
      "# 7 번째 category (tokens): 7858\n",
      "# voca size: 523 \n",
      "\n",
      "# 8 번째 category (tokens): 7126\n",
      "# voca size: 532 \n",
      "\n",
      "# 9 번째 category (tokens): 6125\n",
      "# voca size: 438 \n",
      "\n",
      "# 10 번째 category (tokens): 5492\n",
      "# voca size: 393 \n",
      "\n",
      "# 11 번째 category (tokens): 4015\n",
      "# voca size: 320 \n",
      "\n",
      "# 12 번째 category (tokens): 4292\n",
      "# voca size: 380 \n",
      "\n",
      "# 13 번째 category (tokens): 4229\n",
      "# voca size: 405 \n",
      "\n",
      "# 14 번째 category (tokens): 5829\n",
      "# voca size: 492 \n",
      "\n",
      "# 15 번째 category (tokens): 5447\n",
      "# voca size: 376 \n",
      "\n",
      "# 16 번째 category (tokens): 4014\n",
      "# voca size: 317 \n",
      "\n",
      "# 17 번째 category (tokens): 3415\n",
      "# voca size: 258 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "for category_num in range(18):\n",
    "    data = open('../vocabulary_all_1211/over_del_tokens__/tokens{}__.txt'.format(category_num), 'r', encoding='utf-8')\n",
    "    token = data.readlines()\n",
    "    print(\"#\", category_num, \"번째 category (tokens):\", len(token))\n",
    "    \n",
    "    for i in range(len(token)):\n",
    "        token[i] = token[i].replace('\\n', '')\n",
    "    \n",
    "    setattr(mod, 'tokens{}'.format(category_num), token)\n",
    "    \n",
    "    #voca로도 저장해줍니다, 리스트 형태로 바꿔서 저장해줍시다\n",
    "    voca = list(set(token))\n",
    "    setattr(mod, 'voca{}'.format(category_num), voca)\n",
    "    print(\"# voca size:\", len(voca), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "sp_matrix = vectorizer.fit_transform(category_sum)\n",
    "#print(sp_matrix[0])\n",
    "\n",
    "word2id = defaultdict(lambda : 0)\n",
    "for idx, feature in enumerate(vectorizer.get_feature_names()):\n",
    "    word2id[feature] = idx\n",
    "#print(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 설문조사를 통해 선정한 5개의 카테고리의 TF-IDF를 구합니다\n",
    "# 파이썬개발자[6] 데이터엔지니어[7] 데이터사이언티스트[10] 머신러닝엔지니어[15] 빅데이터엔지니어[16]\n",
    "category = [6, 7, 10, 15, 16] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# category6(파이썬 개발자)의 voca TF-IDF수치 top15\n",
      "\n",
      "python :  0.15644946578141405\n",
      "aws :  0.09471535225685608\n",
      "설계 :  0.06511680467658855\n",
      "java :  0.06427113188858091\n",
      "기반 :  0.06173411352455798\n",
      "기술 :  0.05581440400850447\n",
      "활용 :  0.05496873122049683\n",
      "시스템 :  0.054123058432489185\n",
      "능력 :  0.052431712856473904\n",
      "django :  0.051532097442937345\n",
      "언어 :  0.048203348916435684\n",
      "서버 :  0.04735767612842804\n",
      "대용량 :  0.04735767612842804\n",
      "api :  0.04735767612842804\n",
      "지식 :  0.04482065776440511\n"
     ]
    }
   ],
   "source": [
    "## Ex) category6에서 많이 등장했는데, 나머지 category에서 드물게 등장한 단어 == TF-IDF수치가 높다\n",
    "## category6의 voca의 TF-IDF수치를 확인해보자, >> 확인방법 : print(category_tfidf)\n",
    "\n",
    "import sys\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "for i, sent in enumerate(category_sum):\n",
    "    #print('====== document[%d]' % i, 'category', category[i], '======')\n",
    "    #print( [ (token, sp_matrix[i, word2id[token]]) for token in common_voca ] , '\\n')\n",
    "    a = [ (token, sp_matrix[i, word2id[token]]) for token in voca6 ]\n",
    "    setattr(mod, 'category{}_tfidf'.format(i), a) \n",
    "    \n",
    "    \n",
    "## category6의 voca의 TF-IDF수치 top10!!\n",
    "print('# category6(파이썬 개발자)의 voca TF-IDF수치 top15\\n')\n",
    "\n",
    "token = []\n",
    "tfidf = []\n",
    "for i in category6_tfidf:\n",
    "    token.append(i[0])\n",
    "    tfidf.append(i[1])\n",
    " \n",
    "\n",
    "a = []\n",
    "top = sorted(range(len(tfidf)),key= lambda i: tfidf[i])[-15:]  # tfidf수치 상위 10개의 인덱스 추출\n",
    "for i in category6_tfidf:\n",
    "    for idx in top:\n",
    "        if (i[0] == token[idx]):\n",
    "            a.append(i)\n",
    "p = []\n",
    "for i in a:\n",
    "    p.append(i[1])\n",
    "p = sorted(p, reverse=True)\n",
    "ttt = []\n",
    "for i in p:\n",
    "    for j in a:\n",
    "        if (i == j[1]):\n",
    "            ttt.append(j)\n",
    "            #print(j)\n",
    "\n",
    "ttt = list(set(ttt))\n",
    "trtr = []\n",
    "for i in ttt:\n",
    "    ap = [i[1], i[0]]\n",
    "    trtr.append(ap) \n",
    "#print(trtr)\n",
    "\n",
    "final = sorted(trtr, reverse=True)\n",
    "\n",
    "for i in final:\n",
    "    print(i[1], \": \", i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# category7(데이터엔지니어)의 voca TF-IDF수치 top15\n",
      "\n",
      "분석 :  0.12127361457323602\n",
      "python :  0.10565504299941017\n",
      "aws :  0.08911773192124162\n",
      "능력 :  0.08268655539084274\n",
      "sql :  0.08268655539084274\n",
      "spark :  0.0755362293202715\n",
      "시스템 :  0.07349916034741577\n",
      "처리 :  0.07074294183438767\n",
      "활용 :  0.06982420233004498\n",
      "대용량 :  0.06706798381701688\n",
      "data :  0.06682051055254787\n",
      "기반 :  0.0643117653039888\n",
      "db :  0.059718067782275314\n",
      "3년 :  0.059718067782275314\n",
      "java :  0.05788058877358992\n"
     ]
    }
   ],
   "source": [
    "## category7\n",
    "\n",
    "for i, sent in enumerate(category_sum):\n",
    "    #print('====== document[%d]' % i, 'category', category[i], '======')\n",
    "    #print( [ (token, sp_matrix[i, word2id[token]]) for token in common_voca ] , '\\n')\n",
    "    a = [ (token, sp_matrix[i, word2id[token]]) for token in voca7 ]\n",
    "    setattr(mod, 'category{}_tfidf'.format(i), a) \n",
    "    \n",
    "    \n",
    "## category7의 voca의 TF-IDF수치 top10!!\n",
    "print('# category7(데이터엔지니어)의 voca TF-IDF수치 top15\\n')\n",
    "\n",
    "token = []\n",
    "tfidf = []\n",
    "for i in category7_tfidf:\n",
    "    token.append(i[0])\n",
    "    tfidf.append(i[1])\n",
    " \n",
    "\n",
    "a = []\n",
    "top = sorted(range(len(tfidf)),key= lambda i: tfidf[i])[-15:]  # tfidf수치 상위 10개의 인덱스 추출\n",
    "for i in category7_tfidf:\n",
    "    for idx in top:\n",
    "        if (i[0] == token[idx]):\n",
    "            a.append(i)\n",
    "p = []\n",
    "for i in a:\n",
    "    p.append(i[1])\n",
    "p = sorted(p, reverse=True)\n",
    "ttt = []\n",
    "for i in p:\n",
    "    for j in a:\n",
    "        if (i == j[1]):\n",
    "            ttt.append(j)\n",
    "            #print(j)\n",
    "\n",
    "ttt = list(set(ttt))\n",
    "trtr = []\n",
    "for i in ttt:\n",
    "    ap = [i[1], i[0]]\n",
    "    trtr.append(ap) \n",
    "#print(trtr)\n",
    "\n",
    "final = sorted(trtr, reverse=True)\n",
    "\n",
    "for i in final:\n",
    "    print(i[1], \": \", i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# category10(데이터 사이언티스트)의 voca TF-IDF수치 top15\n",
      "\n",
      "분석 :  0.24021803680049664\n",
      "능력 :  0.12010901840024832\n",
      "python :  0.11244248531087077\n",
      "머신러닝 :  0.1121659831606466\n",
      "통계 :  0.08530933930528052\n",
      "활용 :  0.07794308640867179\n",
      "sql :  0.07538757537887927\n",
      "data :  0.07003569066257244\n",
      "기반 :  0.06772104228950171\n",
      "우대 :  0.06644328677460545\n",
      "커뮤니케이션 :  0.05749899817033165\n",
      "aws :  0.05749899817033165\n",
      "딥러닝 :  0.05671059245978553\n",
      "시각화 :  0.05337467525626874\n",
      "모델링 :  0.05252676799692933\n"
     ]
    }
   ],
   "source": [
    "## category10\n",
    "\n",
    "for i, sent in enumerate(category_sum):\n",
    "    #print('====== document[%d]' % i, 'category', category[i], '======')\n",
    "    #print( [ (token, sp_matrix[i, word2id[token]]) for token in common_voca ] , '\\n')\n",
    "    a = [ (token, sp_matrix[i, word2id[token]]) for token in voca10 ]\n",
    "    setattr(mod, 'category{}_tfidf'.format(i), a) \n",
    "    \n",
    "    \n",
    "## category10의 voca의 TF-IDF수치 top10!!\n",
    "print('# category10(데이터 사이언티스트)의 voca TF-IDF수치 top15\\n')\n",
    "\n",
    "token = []\n",
    "tfidf = []\n",
    "for i in category10_tfidf:\n",
    "    token.append(i[0])\n",
    "    tfidf.append(i[1])\n",
    " \n",
    "\n",
    "a = []\n",
    "top = sorted(range(len(tfidf)),key= lambda i: tfidf[i])[-15:]  # tfidf수치 상위 10개의 인덱스 추출\n",
    "for i in category10_tfidf:\n",
    "    for idx in top:\n",
    "        if (i[0] == token[idx]):\n",
    "            a.append(i)\n",
    "p = []\n",
    "for i in a:\n",
    "    p.append(i[1])\n",
    "p = sorted(p, reverse=True)\n",
    "ttt = []\n",
    "for i in p:\n",
    "    for j in a:\n",
    "        if (i == j[1]):\n",
    "            ttt.append(j)\n",
    "            #print(j)\n",
    "\n",
    "ttt = list(set(ttt))\n",
    "trtr = []\n",
    "for i in ttt:\n",
    "    ap = [i[1], i[0]]\n",
    "    trtr.append(ap) \n",
    "#print(trtr)\n",
    "\n",
    "final = sorted(trtr, reverse=True)\n",
    "\n",
    "for i in final:\n",
    "    print(i[1], \": \", i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# category15(머신러닝 엔지니어)의 voca TF-IDF수치 top15\n",
      "\n",
      "머신러닝 :  0.16752495835729023\n",
      "딥러닝 :  0.14219215884468006\n",
      "python :  0.13815214477258994\n",
      "분석 :  0.12221151268344495\n",
      "tensorflow :  0.10037728776480521\n",
      "능력 :  0.09697217854229871\n",
      "pytorch :  0.08843658659852052\n",
      "learning :  0.0841397853322632\n",
      "연구 :  0.08047767607360021\n",
      "프로젝트 :  0.07173284440115248\n",
      "분야 :  0.07173284440115248\n",
      "deep :  0.06898086520594303\n",
      "논문 :  0.0678587813307673\n",
      "ml :  0.06693678781643583\n",
      "기반 :  0.06641930037143748\n"
     ]
    }
   ],
   "source": [
    "## category15\n",
    "\n",
    "for i, sent in enumerate(category_sum):\n",
    "    #print('====== document[%d]' % i, 'category', category[i], '======')\n",
    "    #print( [ (token, sp_matrix[i, word2id[token]]) for token in common_voca ] , '\\n')\n",
    "    a = [ (token, sp_matrix[i, word2id[token]]) for token in voca15 ]\n",
    "    setattr(mod, 'category{}_tfidf'.format(i), a) \n",
    "    \n",
    "    \n",
    "## category15의 voca의 TF-IDF수치 top10!!\n",
    "print('# category15(머신러닝 엔지니어)의 voca TF-IDF수치 top15\\n')\n",
    "\n",
    "token = []\n",
    "tfidf = []\n",
    "for i in category15_tfidf:\n",
    "    token.append(i[0])\n",
    "    tfidf.append(i[1])\n",
    " \n",
    "\n",
    "a = []\n",
    "top = sorted(range(len(tfidf)),key= lambda i: tfidf[i])[-15:]  # tfidf수치 상위 10개의 인덱스 추출\n",
    "for i in category15_tfidf:\n",
    "    for idx in top:\n",
    "        if (i[0] == token[idx]):\n",
    "            a.append(i)\n",
    "p = []\n",
    "for i in a:\n",
    "    p.append(i[1])\n",
    "p = sorted(p, reverse=True)\n",
    "ttt = []\n",
    "for i in p:\n",
    "    for j in a:\n",
    "        if (i == j[1]):\n",
    "            ttt.append(j)\n",
    "            #print(j)\n",
    "\n",
    "ttt = list(set(ttt))\n",
    "trtr = []\n",
    "for i in ttt:\n",
    "    ap = [i[1], i[0]]\n",
    "    trtr.append(ap) \n",
    "#print(trtr)\n",
    "\n",
    "final = sorted(trtr, reverse=True)\n",
    "\n",
    "for i in final:\n",
    "    print(i[1], \": \", i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# category16(빅데이터 엔지니어)의 voca TF-IDF수치 top15\n",
      "\n",
      "분석 :  0.13627712416801765\n",
      "python :  0.11518661685630063\n",
      "능력 :  0.09734080297715547\n",
      "머신러닝 :  0.08223990223995611\n",
      "aws :  0.0794949890980103\n",
      "기반 :  0.07138325551658067\n",
      "활용 :  0.06651621536772291\n",
      "빅데이터 :  0.06418724077264867\n",
      "처리 :  0.06327152193515105\n",
      "spark :  0.05985218733103613\n",
      "data :  0.05985218733103613\n",
      "딥러닝 :  0.05929788571417938\n",
      "시스템 :  0.05840448178629328\n",
      "대용량 :  0.05840448178629328\n",
      "설계 :  0.053537441637435505\n"
     ]
    }
   ],
   "source": [
    "## category16\n",
    "\n",
    "for i, sent in enumerate(category_sum):\n",
    "    #print('====== document[%d]' % i, 'category', category[i], '======')\n",
    "    #print( [ (token, sp_matrix[i, word2id[token]]) for token in common_voca ] , '\\n')\n",
    "    a = [ (token, sp_matrix[i, word2id[token]]) for token in voca16 ]\n",
    "    setattr(mod, 'category{}_tfidf'.format(i), a) \n",
    "    \n",
    "    \n",
    "## category16의 voca의 TF-IDF수치 top10!!\n",
    "print('# category16(빅데이터 엔지니어)의 voca TF-IDF수치 top15\\n')\n",
    "\n",
    "token = []\n",
    "tfidf = []\n",
    "for i in category16_tfidf:\n",
    "    token.append(i[0])\n",
    "    tfidf.append(i[1])\n",
    " \n",
    "\n",
    "a = []\n",
    "top = sorted(range(len(tfidf)),key= lambda i: tfidf[i])[-15:]  # tfidf수치 상위 10개의 인덱스 추출\n",
    "for i in category16_tfidf:\n",
    "    for idx in top:\n",
    "        if (i[0] == token[idx]):\n",
    "            a.append(i)\n",
    "p = []\n",
    "for i in a:\n",
    "    p.append(i[1])\n",
    "p = sorted(p, reverse=True)\n",
    "ttt = []\n",
    "for i in p:\n",
    "    for j in a:\n",
    "        if (i == j[1]):\n",
    "            ttt.append(j)\n",
    "            #print(j)\n",
    "\n",
    "ttt = list(set(ttt))\n",
    "trtr = []\n",
    "for i in ttt:\n",
    "    ap = [i[1], i[0]]\n",
    "    trtr.append(ap) \n",
    "#print(trtr)\n",
    "\n",
    "final = sorted(trtr, reverse=True)\n",
    "\n",
    "for i in final:\n",
    "    print(i[1], \": \", i[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
