{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 12월 11일 기준 크롤링 데이터 클렌징 (총 18개의 카테고리입니다.) _all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열 클렌징 함수 정의\n",
    "\n",
    "def cleansing(text):\n",
    "    pattern = '([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)' # E-mail주소제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+' # URL제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '([ㄱ-ㅎㅏ-ㅣ]+)' # 한글 자음, 모음 제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '[-=.,•\\?:^$@*\\\"“※~&%→∙ㆍ·★​◆⅓✔︎★●⦁↑●◆☞”“’■▪️◾▶!]' # 특정 특수문자 제거 (+,#는 C++,C#때문에 포함X)\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '[/』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》【】]'  # 특정 특수문자 제거2\n",
    "    text = re.sub(pattern=pattern, repl=' ', string=text)\n",
    "    #괄호들과 / 에는 ' ' 을 넣어줬다\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746\n",
      "683\n",
      "624\n",
      "494\n",
      "287\n",
      "274\n",
      "256\n",
      "233\n",
      "220\n",
      "193\n",
      "163\n",
      "148\n",
      "168\n",
      "141\n",
      "171\n",
      "162\n",
      "137\n",
      "109\n"
     ]
    }
   ],
   "source": [
    "category = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
    "\n",
    "for category_num in category:\n",
    "    data = open('../crawling_all_1211/category{0}.txt'.format(category_num), 'r', encoding = 'utf-8')\n",
    "    lines = data.readlines()  # 데이터 불러와서 line 단위로 넣는다\n",
    "        \n",
    "    import re\n",
    "    \n",
    "    line_list = []\n",
    "    for i in range(len(lines)):\n",
    "        # split을 사용하면 '우대사항'이라는 글자가 여러개 있을 때, 문장이 여러개로 나눠지기 때문에 partition 사용\n",
    "        part = lines[i].partition('우대사항') \n",
    "        part = list(part)  # partition은 저장형태가 튜플이기 때문에  list로 바꿔준다\n",
    "        if '우대사항' in part:\n",
    "            part.remove('우대사항')  # '우대사항' 글자 자체는 필요없기때문에 리스트에서 지워준다\n",
    "        line_list.append(part)\n",
    "        \n",
    "    for i in range(len(line_list)):\n",
    "        for j in range(len(line_list[i])):\n",
    "            line_list[i][j] = cleansing(line_list[i][j])  # 위에 정의한 cleasing함수로 데이터 클렌징\n",
    "    \n",
    "    for i in range(len(line_list)):\n",
    "        for j in range(len(line_list[i])):\n",
    "            line_list[i][j] = ' '.join(line_list[i][j].split())  # 다중공백 치환\n",
    "\n",
    "    for i in range(len(line_list)):\n",
    "        a = []\n",
    "        a.append(' '.join(line_list[i]))\n",
    "        line_list[i] = a\n",
    "        \n",
    "    print(len(line_list)) # 각 카테고리별 크롤링 데이터 개수 print\n",
    "    data_len = len(line_list)\n",
    "    \n",
    "    \n",
    "    line = '\\n'.join(sum(line_list, [])) \n",
    "    # category{0}_list{1}.txt로 새로 저장할 변수입니다.\n",
    "    # \\n으로 구분되어있기 때문에 문장분리(채용공고 별 분리)가 가능합니다.\n",
    "\n",
    "    \n",
    "    f2 = open('data_cleansing_all/cleansing_category{0}_list{1}.txt'.format(category_num,data_len), 'w')\n",
    "    f2.write(line)\n",
    "    f2.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
