{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## least_word_delete (3번 이하 등장 token삭제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14047\n"
     ]
    }
   ],
   "source": [
    "## 우선 tokens6 데이터로 테스트 해본다\n",
    "\n",
    "data = open('../stopwords_filtering/tokens6.txt', 'r', encoding='utf-8')\n",
    "data = data.readlines()\n",
    "print(len(data))\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data[i] = data[i].replace('\\n', '')\n",
    "\n",
    "tokens6 = data\n",
    "#print(tokens6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens6 : [('경험', 1016), ('개발', 565), ('이해', 226), ('python', 212), ('서비스', 208), ('사용', 191), ('운영', 175), ('관련', 140), ('경력', 137), ('활용', 130)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print('tokens6 :', nltk.FreqDist(tokens6).most_common(10)) # 빈도수 top10 찍어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1814\n"
     ]
    }
   ],
   "source": [
    "#tokens6.count('경험')\n",
    "\n",
    "voca = set(tokens6)\n",
    "voca = list(voca)\n",
    "\n",
    "# 1~3번 등장한 단어를 찾아서 least_word 리스트에 추가\n",
    "least_word= []\n",
    "for i in voca:\n",
    "    if tokens6.count(i) < 4:\n",
    "        #print(i, tokens6.count(i))\n",
    "        least_word.append(i)\n",
    "        \n",
    "print(len(least_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2403 -> 589\n"
     ]
    }
   ],
   "source": [
    "# least_word 리스트에 포함되지 않은(4번 이상 등장한)token들만 tokens_ 변수에 저장\n",
    "tokens_ = [w for w in tokens6 if w not in least_word]\n",
    "\n",
    "print(len(set(tokens6)), '->', len(set(tokens_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 6 번째 category (tokens) : 14047\n",
      "# least_word 리스트 : 1814\n",
      "삭제 전 voca : ( 2403 ) -> 삭제 후 voca : ( 589 ) \n",
      "\n",
      "# 7 번째 category (tokens) : 12229\n",
      "# least_word 리스트 : 1529\n",
      "삭제 전 voca : ( 2057 ) -> 삭제 후 voca : ( 528 ) \n",
      "\n",
      "# 12 번째 category (tokens) : 8592\n",
      "# least_word 리스트 : 1278\n",
      "삭제 전 voca : ( 1675 ) -> 삭제 후 voca : ( 397 ) \n",
      "\n",
      "# 13 번째 category (tokens) : 8049\n",
      "# least_word 리스트 : 1330\n",
      "삭제 전 voca : ( 1685 ) -> 삭제 후 voca : ( 355 ) \n",
      "\n",
      "# 15 번째 category (tokens) : 6254\n",
      "# least_word 리스트 : 1040\n",
      "삭제 전 voca : ( 1361 ) -> 삭제 후 voca : ( 321 ) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# category6,7,12,13,15 (11월08일 기준 크롤링 데이터) 에 적용해보기\n",
    "\n",
    "import sys\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "category = [6, 7, 12, 13, 15]\n",
    "\n",
    "for i in category:\n",
    "    data = open('../stopwords_filtering/tokens{}.txt'.format(i), 'r', encoding='utf-8')\n",
    "    token = data.readlines()\n",
    "    print(\"#\", i, \"번째 category (tokens) :\", len(token))\n",
    "    \n",
    "    for j in range(len(token)):\n",
    "        token[j] = token[j].replace('\\n', '')\n",
    "    \n",
    "    \n",
    "    voca = set(token)\n",
    "    voca = list(voca)\n",
    "\n",
    "    # 1~3번 등장한 단어를 찾아서 least_word 리스트에 추가\n",
    "    least_word= []\n",
    "    for j in voca:\n",
    "        if token.count(j) < 4:\n",
    "            least_word.append(j)\n",
    "    print(\"# least_word 리스트 :\", len(least_word))\n",
    "    \n",
    "    # least_word 리스트에 포함되지 않은(4번 이상 등장한)token들만 tokens_ 변수에 저장\n",
    "    token_ = [w for w in token if w not in least_word]\n",
    "    print(\"삭제 전 voca : (\", len(set(token)), \") ->\", \"삭제 후 voca : (\" , len(set(token_)), ') \\n')\n",
    "\n",
    "    setattr(mod, 'tokens{}_'.format(i), token_)\n",
    "    \n",
    "#print(tokens7_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "voca6 = set(tokens6_)\n",
    "voca6 = list(voca6)\n",
    "\n",
    "a = {}\n",
    "for i in voca6:\n",
    "    a[i] = tokens6.count(i)\n",
    "    \n",
    "#print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176 : {'git', '유경험자', '컨테이너', '머신러닝', '소프트웨어', '대용량', '제출', '데이터', '논문', '분산', '실무', '석사', '1년', 'cd', 'airflow', '구축', '경력자', '커뮤니케이션', '성능', '원활한', '기반', '인프라', '유관', '개선', '학사', '운영', '사용', '성장', '비즈니스', '우대', '게임', '익숙', '언어', '가능', '수학', 'etl', 'ai', 'tensorflow', '문제해결', '오픈소스', '진행', '학습', '구현', '이론', '실제', '이용', 'experience', '다양', 'nlp', 'sql', '기초', '빅데이터', '도메인', '이해', '해결', '기술', '개발', '추천', '다양한', '적용', 'engineering', '파이썬', '딥러닝', '프레임워크', '엔지니어링', '소통', 'kafka', '열정', '가능자', '금융', '공학', '방법', 'azure', '수행', '파이프라인', '분석', 'r', '해당', 'learning', '클라우드', 'c++', '수집', 'scala', '무관', 'c', '지식', '전공', '관련', '컴퓨터공학', '작성', 'ci', 'java', 'nosql', '관리', '내용', '모바', '업무', '박사', '보유', '역량', 'mysql', '모델링', 'ml', '영어', '시각화', '플랫폼', '통계', '활용', '구성', '보유자', '필요', '이해도', '연구', '검색', '채용', 'hadoop', '설계', '관심', '프로젝트', '전공자', 'aws', '5년', '실시간', '컴퓨터', '적극적', '아키텍처', 'cloud', '분야', '3년', '학력', 'docker', 'elasticsearch', '경험자', 'machine', 'gcp', '2년', '마케팅', '경우', '환경', '능숙', '시스템', 'spark', '기계학습', '프로그래밍', 'deep', 'pytorch', 'data', '통계학', '중급', '학위', '문제', 'rdbms', '자료구조', '모델', '데이터베이스', '로직', 'python', '협업', '경력', '도구', '경험', '러닝', 'computer', '알고리즘', '1개', '능력', 'google', 'system', '기본적', '기본', '처리', 'framework', '서버', '조직', '배포', '서비스'}\n"
     ]
    }
   ],
   "source": [
    "voca6 = set(tokens6_)\n",
    "voca7 = set(tokens7_)\n",
    "voca12 = set(tokens12_)\n",
    "voca13 = set(tokens13_)\n",
    "voca15 = set(tokens15_)\n",
    "\n",
    "common_voca = voca6 & voca7 & voca12 & voca13 & voca15\n",
    "print(len(common_voca), ':', common_voca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
